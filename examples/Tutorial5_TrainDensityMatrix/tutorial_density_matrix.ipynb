{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction of a density matrix\n",
    "\n",
    "In this tutorial, a walkthrough of how to reconstruct a density matrix via training a pair of modified *Restricted Boltzmann Machines* is presented\n",
    "\n",
    "\n",
    "## The density matrix to be reconstructed\n",
    "The density matrix that will be be reconstructed is the density matrix associated with the 2-qubit W state\n",
    "\n",
    "\\begin{equation}\n",
    "            \\vert\\psi \\rangle = \\frac{1}{\\sqrt{2}}\\vert 01\\rangle + \\frac{1}{\\sqrt{2}}\\vert10\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "so that\n",
    "\n",
    "\\begin{equation}\n",
    "            \\rho = \\vert\\psi\\rangle\\langle\\psi\\vert\n",
    "\\end{equation}\n",
    "\n",
    "with global depolarization probability $p_{dep} = 0.5$ such that\n",
    "\n",
    "\\begin{equation}\n",
    "            \\rho_{new} = \\left(1 - p_{dep}\\right)\\rho + \\frac{p_{dep}}{2^N} I\n",
    "\\end{equation}\n",
    "\n",
    "where $I$ is the identity matrix, representing the maximally mixed state.\n",
    "\n",
    "The example dataset, `N2_W_state_data.txt`, is comprised of 900 $\\sigma$ measurements, 100 in each of the $3^2$ permuations of two of the bases X, Y and Z. A corresponding file containing the bases for each data point in `N2_W_state_data.txt`, `N2_W_state_bases.txt`, is also required. The set of all 3^2 bases in which measurements are made is stored in `N2_IC_bases.txt`. Finally, the real and imaginary parts of the matrix are stored in `N2_W_state_target_real.txt` and `N2_W_state_target_imag.txt` respectively. As per convention, spins are represented in binary notation with zero and one denoting spin-up and spin-down, respectively.\n",
    "\n",
    "## Using qucumber to reconstruct the density matrix\n",
    "\n",
    "### Imports\n",
    "To begin the tutorial, first import the required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.cplx as cplx\n",
    "\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python class `DensityMatrix` contains the properties of an RBM needed to reconstruct the density matrix, as demonstrated in [this paper here].\n",
    "\n",
    "To instantiate a `DensityMatrix` object, one needs to specify the number of visible, hidden and auxiliary units in the RBM. The number of visible units, `num_visible`, is given by the size of the physical system, i.e. the number of spins or qubits (2 in this case). On the other hand, the number of hidden units, `num_hidden`, can be varied to change the expressiveness of the neural network, and the number of auxiliary units, `num_aux`, can be varied depending on the extent of purification required of the system.\n",
    "\n",
    "On top of needing the number of visible, hidden and auxiliary units, a `DensityMatrix` object requires the user to input a dictionary containing the unitary operators (2x2) that will be used to rotate the qubits in and out of the computational basis, Z, during the training process. The `unitaries` utility will take care of creating this dictionary.\n",
    "\n",
    "The `MetricEvaluator` class and `training_statistics` utility are built-in amenities that will allow the user to evaluate the training in real time. \n",
    "\n",
    "Lastly, the `cplx` utility allows QuCumber to be able to handle complex numbers. Currently, PyTorch does not support complex numbers.\n",
    "\n",
    "\n",
    "### Training\n",
    "To evaluate the training in real time, the fidelity between the true wavefunction of the system and the wavefunction that QuCumber reconstructs, \n",
    "\n",
    "\\begin{equation}\n",
    "\\operatorname{Tr }\\sqrt{\\sqrt{\\rho_{RBM}}\\rho\\sqrt{\\rho_{RBM}}}\n",
    "\\end{equation}\n",
    "will be calculated along with the Kullback-Leibler (KL) divergence (the RBM's cost function). First, the training data and the true wavefunction of this system need to be loaded using the `data` utility.\n",
    "\n",
    "[this paper here]: https://arxiv.org/pdf/1801.09684.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_path = \"N2_W_state_data.txt\"\n",
    "train_bases_path = \"N2_W_state_bases.txt\"\n",
    "matrix_path_real = \"N2_W_state_target_real.txt\"\n",
    "matrix_path_imag = \"N2_W_state_target_imag.txt\"\n",
    "bases_path = \"N2_IC_bases.txt\"\n",
    "\n",
    "\n",
    "train_samples, train_bases, bases = data.load_data(\n",
    "    train_path, tr_bases_path=train_bases_path, bases_path=bases_path\n",
    ")\n",
    "\n",
    "true_matrix_real = data.load_data(matrix_path_real)[0]\n",
    "true_matrix_imag = data.load_data(matrix_path_imag)[0]\n",
    "\n",
    "true_matrix = cplx.make_complex(true_matrix_real, true_matrix_imag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `N2_all_bases.txt` contains every unique basis in the `N2_W_state_p0.50_100_samples_data.txt` file. Calculation of the full KL divergence in every basis requires the user to specify each unique basis.\n",
    "\n",
    "As previously mentioned, a `DensityMatrix` object requires a dictionary that contains the unitary operators that will be used to rotate the qubits in and out of the computational basis, Z, during the training process. In the case of the provided dataset, the unitaries required are the well-known $H$, and $K$ gates. The dictionary needed can be created with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_dict = unitaries.create_dict()\n",
    "# unitary_dict = unitaries.create_dict(unitary_name=torch.tensor([[real part],\n",
    "#                                                                 [imaginary part]],\n",
    "#                                                                 dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wishes to add their own unitary operators from their experiment to `unitary_dict`, uncomment the block above. When `unitaries.create_dict()` is called, it will contain the identity and the $H$ and $K$ gates by default under the keys \"Z\", \"X\" and \"Y\", respectively.\n",
    "\n",
    "The number of visible units in the RBM is equal to the number of qubits. The number of hidden units will also be taken to be the number of visible units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = train_samples.shape[-1]\n",
    "nh = 1\n",
    "na = 2\n",
    "\n",
    "nn_state = DensityMatrix(\n",
    "    num_visible=nv, num_hidden=nh, num_aux=na, unitary_dict=unitary_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of visible, hidden, and auxiliary units must now be specified. These are given by `nv`, `nh` and `na` respectively. The number of visible units is equal to the size of the system. The hidden and auxiliary units are hyperparameters that must be determiend by the user. With these, a `DensityMatrix` object can be instantiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the hyperparameters of the training process can be specified. \n",
    "\n",
    "1. `epochs`: the total number of training cycles that will be performed (default = 100)\n",
    "2. `pos_batch_size`: the number of data points used in the positive phase of the gradient (default = 100)\n",
    "3. `neg_batch_size`: the number of data points used in the negative phase of the gradient (default = `pos_batch_size`)\n",
    "4. `k`: the number of contrastive divergence steps (default = 1)\n",
    "5. `lr`: coefficient that scales the default value of the (non-constant) learning rate of the Adadelta algorithm (default = 1)\n",
    "\n",
    "    **Note:** For more information on the hyperparameters above, it is strongly encouraged that the user to read through the brief, but thorough theory document on RBMs. One does not have to specify these hyperparameters, as their default values will be used without the user overwriting them. It is recommended to keep with the default values until the user has a stronger grasp on what these hyperparameters mean. The quality and the computational efficiency of the training will highly depend on the choice of hyperparameters. As such, playing around with the hyperparameters is almost always necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "pbs = 10  # pos_batch_size\n",
    "nbs = 10  # neg_batch_size\n",
    "lr = 5\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating the training in real time, the `MetricEvaluator` will be called to calculate the training evaluators every `period` epochs. The `MetricEvaluator` requires the following arguments.\n",
    "\n",
    "1. `period`: the frequency of the training evaluators being calculated (e.g. `period=200` means that the `MetricEvaluator` will compute the desired metrics every 200 epochs)\n",
    "2. A dictionary of functions you would like to reference to evaluate the training (arguments required for these functions are keyword arguments placed after the dictionary)\n",
    "\n",
    "The following additional arguments are needed to calculate the fidelity and KL divergence in the `training_statistics` utility.\n",
    "\n",
    "- `target_matrix` (the true density matrix of the system)\n",
    "- `space` (the entire Hilbert space of the system)\n",
    "\n",
    "The training evaluators can be printed out via the `verbose=True` statement.\n",
    "\n",
    "Although the fidelity and KL divergence are excellent training evaluators, they are not practical to calculate in most cases; the user may not have access to the target wavefunction of the system, nor may generating the Hilbert space of the system be computationally feasible. However, evaluating the training in real time is extremely convenient. \n",
    "\n",
    "Any custom function that the user would like to use to evaluate the training can be given to the `MetricEvaluator`, thus avoiding having to calculate fidelity and/or KL divergence. As an example, a function to compute the partition function of the current density matrix is presented. Any custom function given to `MetricEvaluator` must take the neural-network state (in this case, the `Density` object) and keyword arguments. Although the given example requires the Hilbert space to be computed, the scope of the `MetricEvaluator`'s ability to be able to handle any function should still be evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(nn_state, space, **kwargs):\n",
    "    a_space = nn_state.generate_space(nn_state.num_aux)\n",
    "    return nn_state.rbm_am.partition(space, a_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Hilbert space of the system must be generated for the fidelity and KL divergence and the dictionary of functions the user would like to compute every `period` epochs must be given to the `MetricEvaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 1\n",
    "space = nn_state.generate_hilbert_space(nv)\n",
    "aux_space = nn_state.generate_hilbert_space(na)\n",
    "\n",
    "callbacks = [\n",
    "    MetricEvaluator(\n",
    "        period,\n",
    "        {\n",
    "            \"Density Matrix Fidelity\": ts.density_matrix_fidelity,\n",
    "            \"Density Matrix KL\": ts.density_matrix_KL,\n",
    "            # \"Partition Function\": partition\n",
    "        },\n",
    "        target=true_matrix,\n",
    "        bases=bases,\n",
    "        verbose=True,\n",
    "        v_space=space,\n",
    "        a_space=aux_space,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training can begin. The `DensityMatrix` object has a function called `fit` which takes care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112d61932fae4eb7b108e5248adbdbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs ', max=250, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tDensity Matrix Fidelity = 0.641332\tDensity Matrix KL = 0.474613\n",
      "Epoch: 2\tDensity Matrix Fidelity = 0.650911\tDensity Matrix KL = 0.444645\n",
      "Epoch: 3\tDensity Matrix Fidelity = 0.678865\tDensity Matrix KL = 0.425416\n",
      "Epoch: 4\tDensity Matrix Fidelity = 0.719939\tDensity Matrix KL = 0.377686\n",
      "Epoch: 5\tDensity Matrix Fidelity = 0.796993\tDensity Matrix KL = 0.265148\n",
      "Epoch: 6\tDensity Matrix Fidelity = 0.893291\tDensity Matrix KL = 0.090332\n",
      "Epoch: 7\tDensity Matrix Fidelity = 0.909510\tDensity Matrix KL = 0.051538\n",
      "Epoch: 8\tDensity Matrix Fidelity = 0.918888\tDensity Matrix KL = 0.034224\n",
      "Epoch: 9\tDensity Matrix Fidelity = 0.929784\tDensity Matrix KL = 0.035206\n",
      "Epoch: 10\tDensity Matrix Fidelity = 0.926544\tDensity Matrix KL = 0.037504\n",
      "Epoch: 11\tDensity Matrix Fidelity = 0.888845\tDensity Matrix KL = 0.046477\n",
      "Epoch: 12\tDensity Matrix Fidelity = 0.938697\tDensity Matrix KL = 0.031310\n",
      "Epoch: 13\tDensity Matrix Fidelity = 0.940024\tDensity Matrix KL = 0.034907\n",
      "Epoch: 14\tDensity Matrix Fidelity = 0.948373\tDensity Matrix KL = 0.031642\n",
      "Epoch: 15\tDensity Matrix Fidelity = 0.934155\tDensity Matrix KL = 0.040382\n",
      "Epoch: 16\tDensity Matrix Fidelity = 0.951063\tDensity Matrix KL = 0.026191\n",
      "Epoch: 17\tDensity Matrix Fidelity = 0.940883\tDensity Matrix KL = 0.046272\n",
      "Epoch: 18\tDensity Matrix Fidelity = 0.952244\tDensity Matrix KL = 0.026002\n",
      "Epoch: 19\tDensity Matrix Fidelity = 0.948315\tDensity Matrix KL = 0.031537\n",
      "Epoch: 20\tDensity Matrix Fidelity = 0.953650\tDensity Matrix KL = 0.029653\n",
      "Epoch: 21\tDensity Matrix Fidelity = 0.947361\tDensity Matrix KL = 0.032965\n",
      "Epoch: 22\tDensity Matrix Fidelity = 0.948025\tDensity Matrix KL = 0.034786\n",
      "Epoch: 23\tDensity Matrix Fidelity = 0.957214\tDensity Matrix KL = 0.022769\n",
      "Epoch: 24\tDensity Matrix Fidelity = 0.954836\tDensity Matrix KL = 0.031515\n",
      "Epoch: 25\tDensity Matrix Fidelity = 0.952031\tDensity Matrix KL = 0.030576\n",
      "Epoch: 26\tDensity Matrix Fidelity = 0.940423\tDensity Matrix KL = 0.040809\n",
      "Epoch: 27\tDensity Matrix Fidelity = 0.959577\tDensity Matrix KL = 0.027155\n",
      "Epoch: 28\tDensity Matrix Fidelity = 0.947516\tDensity Matrix KL = 0.043721\n",
      "Epoch: 29\tDensity Matrix Fidelity = 0.952256\tDensity Matrix KL = 0.036983\n",
      "Epoch: 30\tDensity Matrix Fidelity = 0.963152\tDensity Matrix KL = 0.022425\n",
      "Epoch: 31\tDensity Matrix Fidelity = 0.968632\tDensity Matrix KL = 0.017776\n",
      "Epoch: 32\tDensity Matrix Fidelity = 0.973835\tDensity Matrix KL = 0.014434\n",
      "Epoch: 33\tDensity Matrix Fidelity = 0.972966\tDensity Matrix KL = 0.020754\n",
      "Epoch: 34\tDensity Matrix Fidelity = 0.979271\tDensity Matrix KL = 0.014295\n",
      "Epoch: 35\tDensity Matrix Fidelity = 0.978261\tDensity Matrix KL = 0.012446\n",
      "Epoch: 36\tDensity Matrix Fidelity = 0.977714\tDensity Matrix KL = 0.017552\n",
      "Epoch: 37\tDensity Matrix Fidelity = 0.983515\tDensity Matrix KL = 0.009491\n",
      "Epoch: 38\tDensity Matrix Fidelity = 0.981712\tDensity Matrix KL = 0.011184\n",
      "Epoch: 39\tDensity Matrix Fidelity = 0.967727\tDensity Matrix KL = 0.022806\n",
      "Epoch: 40\tDensity Matrix Fidelity = 0.968437\tDensity Matrix KL = 0.025722\n",
      "Epoch: 41\tDensity Matrix Fidelity = 0.979346\tDensity Matrix KL = 0.012163\n",
      "Epoch: 42\tDensity Matrix Fidelity = 0.972174\tDensity Matrix KL = 0.016422\n",
      "Epoch: 43\tDensity Matrix Fidelity = 0.971053\tDensity Matrix KL = 0.018585\n"
     ]
    }
   ],
   "source": [
    "nn_state.fit(\n",
    "    train_samples,\n",
    "    train_bases,\n",
    "    true_matrix,\n",
    "    epochs=epochs,\n",
    "    pos_batch_size=pbs,\n",
    "    neg_batch_size=nbs,\n",
    "    lr=lr,\n",
    "    k=k,\n",
    "    bases=bases,\n",
    "    progbar=\"notebook\",\n",
    "    callbacks=callbacks,\n",
    "    train_to_fid=0.999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn_state.rbm_am.weights_W)\n",
    "print(nn_state.rbm_am.weights_U)\n",
    "print(nn_state.rbm_am.visible_bias)\n",
    "print(nn_state.rbm_am.hidden_bias)\n",
    "print(nn_state.rbm_am.aux_bias)\n",
    "print(nn_state.rbm_ph.weights_W)\n",
    "print(nn_state.rbm_ph.weights_U)\n",
    "print(nn_state.rbm_ph.visible_bias)\n",
    "print(nn_state.rbm_ph.hidden_bias)\n",
    "print(nn_state.rbm_ph.aux_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these training evaluators can be accessed after the training has completed, as well. The code below shows this, along with plots of each training evaluator versus the training cycle number (epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelities = callbacks[0][\"Density Matrix Fidelity\"]\n",
    "KLs = callbacks[0][\"Density Matrix KL\"]\n",
    "epoch = np.arange(period, epochs + 1, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters to make the plots look nice\n",
    "\n",
    "\"\"\"params = {\n",
    "text.usetex: True,\n",
    "font.family: serif,\n",
    "legend.fontsize: 14,\n",
    "figure.figsize: (10, 3),\n",
    "axes.labelsize: 16,\n",
    "xtick.labelsize: 14,\n",
    "ytick.labelsize: 14,\n",
    "lines.linewidth: 2,\n",
    "lines.markeredgewidth: 0.8,\n",
    "lines.markersize: 5,\n",
    "lines.marker: o,\n",
    "patch.edgecolor: black,\n",
    "},\n",
    "plt.rcParams.update(params),\n",
    "plt.style.use(seaborn-deep)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 3))\n",
    "ax = axs[0]\n",
    "ax.plot(epoch, fidelities, \"o\", color=\"C0\", markeredgecolor=\"black\")\n",
    "ax.set_ylabel(r\"Fidelity\")\n",
    "ax.set_xlabel(r\"Epoch\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(epoch, KLs, \"o\", color=\"C1\", markeredgecolor=\"black\")\n",
    "ax.set_ylabel(r\"KL Divergence\")\n",
    "ax.set_xlabel(r\"Epoch\")\n",
    "\n",
    "# ax = axs[2]\n",
    "# ax.plot(epoch, partition, \"o\", color=\"C2\", markeredgecolor=\"black\")\n",
    "# ax.set_ylabel(r\"$\\vert\\alpha\\vert$\")\n",
    "# ax.set_xlabel(r\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the weights, visible biases and hidden biases as torch tensors with the following keys: \"weights\", \"visible_bias\", \"hidden_bias\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state.save(\"saved_params_W_state.pt\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
